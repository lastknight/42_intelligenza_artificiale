# Executive Summary – Che cosa prevede l’AI Act?

L’AI Act è una normativa che ha l’ambizione di fornire un framework normativo sia per chi realizza Intelligenza Artificiale sia per chi la utilizza. La Proposta normativa si basa su un sistema di classificazione volto a determinare il **livello di rischio** che una tecnologia di AI potrebbe rappresentare per la salute, la sicurezza e i diritti fondamentali delle persone.

Se volessimo sintetizzarla in cinque punti potremmo dire che: 

1. Come la normativa a tutela dei dati personali (GDPR), questa è una normativa risk-based dove i vari player (fornitori di AI e utilizzatori di AI) dovranno fare una **valutazione di impatto** per determinare la legittimità dello strumento di Intelligenza Artificiale usato. La valutazione di impatto non sarà solo sui profili privacy e cybersecurity, ma anche e soprattutto sulla possibile lesione dei diritti umani e sugli impatti etici e sociali.
2. Il regolamento divide tra intelligenze artificiale che creano: (i) un rischio **inaccettabile**; (ii) un rischio **medio-basso**; (iii) un rischio **alto**. A seconda del livello di rischio si prevedono più o meno elevati obblighi di conformità.
3. Il regolamento lascia aperta la porta a **nuove applicazioni di Intelligenza Artificiale** attraverso una normazione che rimanda all’allegato III per definire cosa rientri nel concetto di alto rischio per i diritti dei cittadini europei. 
4. L’Intelligenza Artificiale generativa e quindi **CHATGPT** è stata inserita all’ultimo grazie all’ottimo lavoro del nostro Europarlamentare Brando Benifei, perché sostanzialmente prima non era stata normata. Sotto questo profilo, il Regolamento è molto severo sui dati che un sistema di AI generativa utilizza per rispondere ai quesiti (dataset). Ne consegue che se la normativa fosse già in vigore, CHATGPT avrebbe seri problemi ad essere uno strumento legittimo in Europa. 
5. I tempi per l’approvazione definitiva, dopo la consultazione con Consiglio d’Europa e Commissione, dovrebbero essere approvati per la fine dell’anno. I tempi di entrata in vigore, tuttavia, **sono di 24 mesi** dall’approvazione e quindi, qualora non ci fossero intoppi, dovrebbe entrare in vigore a fine **2025** o, al più tardi, all’inizio del **2026**. 

Che cosa cambierà per le imprese che usano l’AI? 

L’AI avrà degli impatti molto significativi, perché gli obblighi non riguardano solo **chi la realizza**, ma anche **chi la utilizza**. Quindi le imprese che utilizzeranno AI ad alto rischio, dovranno valutare con molta attenzione gli strumenti di Intelligenza Artificiale di cui vogliono dotarsi. 

A seguito di un'analisi dell’AI Act sono emerse, nello specifico, **sette macrocategorie di obblighi**: (i) obblighi relativi alla gestione del rischio, (ii) obblighi relativi alla gestione dei dati, (iii) obblighi di trasparenza, (iv) obblighi di supervisione, (v) obblighi di conformità ai requisiti europei, (vi) obblighi di collaborazione con le Autorità e (vii) obblighi di accuratezza, cybersicurezza e resilienza. 

# Executive Summary – Tutela del copyright nel contesto dell’AI

È innegabile che l'Intelligenza Artificiale (AI) abbia subito una rapida evoluzione nell'ultimo periodo, influenzando diversi ambiti, tra cui l'arte e la musica. Trattandosi di una nuova modalità di creazione di contenuti, è innegabile che nasca una serie di interrogativi legati alla natura dei contenuti ed alla titolarità dei diritti di proprietà intellettuale relativi ai contenuti stessi. 

1. Chi è l’autore di un’opera generata da AI? 
2. Diritti e interessi creativi: fino a che punto si può sperimentare con AI senza mettere in discussione i diritti e gli interessi degli autori originali?
3. Quali sono i rischi sotto il profilo del diritto d’autore per le aziende che decidono di utilizzare prodotti di software di Intelligenza Artificiale?

Comprendere queste questioni è fondamentale nel tentativo di stabilire i limiti e i pericoli nell'utilizzo dell'Intelligenza Artificiale per creare contenuti artistici.

Tuttavia risolvere questi problemi è complesso e, in molti casi, dipende dalle circostanze specifiche. **Gli enti preposti alla registrazione delle opere**, come il Copyright Office statunitense, **tendono a richiedere la paternità umana come requisito per la protezione del copyright** e dello stesso avviso sono anche il legislatore comunitario e quello nazionale italiano.

Le politiche di alcuni software regolamentano la proprietà e l'utilizzo commerciale delle opere generate in base ai termini del servizio e ai piani d'iscrizione degli utenti. La loro disamina è fondamentale per comprendere le possibili implicazioni legali nell'utilizzo di opere generate mediante l’utilizzo di AI.

I più recenti casi che hanno interessato i Tribunali statunitensi hanno evidenziato come l’uso di opere di terzi per l’attività di training dei software di AI espone al rischio concreto di richieste risarcitorie da parte dei soggetti titolari di diritti di proprietà intellettuale sulle opere utilizzate dalle piattaforme come dataset per l’addestramento dei software.

A questo proposito **l’AI Act** ha previsto la possibilità di **richiedere ai fornitori** di sistemi di AI generativa **maggior trasparenza** e moderazione dei contenuti. 